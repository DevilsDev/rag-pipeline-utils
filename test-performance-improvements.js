#!/usr/bin/env node

/**
 * Performance Test Script
 * Tests the performance improvements to ensure identical results with better performance
 */

const { createRagPipeline } = require("./src/core/create-pipeline.js");
const { SampleEmbedder } = require("./src/plugins/sample-embedder.js");
const { SampleRetriever } = require("./src/plugins/sample-retriever.js");
const { LLMReranker } = require("./src/reranker/llm-reranker.js");
const { DAG } = require("./src/dag/dag-engine.js");

// Mock LLM for testing
class MockLLM {
  constructor(options = {}) {
    this.options = options;
  }

  async generate(prompt, context = []) {
    // Simulate processing time
    await new Promise((resolve) => setTimeout(resolve, 10));
    return `Mock response for: ${prompt.substring(0, 50)}... (with ${context.length} context docs)`;
  }
}

// Mock loader for testing
class MockLoader {
  async load(path) {
    console.log(`Loading mock documents from: ${path}`);

    // Generate test documents
    const docs = [];
    for (let i = 0; i < 100; i++) {
      docs.push({
        content: `Test document ${i + 1} content with some sample text for embedding and retrieval testing.`,
        chunk() {
          return [
            `Chunk 1 of doc ${i + 1}`,
            `Chunk 2 of doc ${i + 1}`,
            `Chunk 3 of doc ${i + 1}`,
          ];
        },
      });
    }

    return docs;
  }
}

async function testRerankerBatching() {
  console.log("\nðŸ”„ Testing Reranker Batching Performance...");

  const mockLLM = new MockLLM();
  const reranker = new LLMReranker({
    llm: mockLLM,
    maxTokens: 1000, // Small limit to force batching
    batchSize: 5, // Small batch size for testing
  });

  // Create test documents
  const testDocs = [];
  for (let i = 0; i < 25; i++) {
    testDocs.push({
      text: `Test document ${i + 1} with content for reranking evaluation and testing purposes.`,
      score: Math.random(),
    });
  }

  const query = "test query for reranking";

  console.log(`Reranking ${testDocs.length} documents with batching...`);
  const startTime = Date.now();

  let progressUpdates = 0;
  const rerankedDocs = await reranker.rerank(query, testDocs, {
    onProgress: (progress) => {
      progressUpdates++;
      console.log(
        `  Progress: ${progress.completed}/${progress.total} batches processed`,
      );
    },
  });

  const duration = Date.now() - startTime;

  console.log(`âœ… Reranking completed in ${duration}ms`);
  console.log(`ðŸ“Š Progress updates received: ${progressUpdates}`);
  console.log(`ðŸ“ Results: ${rerankedDocs.length} documents reranked`);

  return { duration, progressUpdates, resultCount: rerankedDocs.length };
}

async function testEmbedderBatching() {
  console.log("\nðŸ”„ Testing Embedder Batching Performance...");

  // Test with environment variable
  process.env.RAG_EMBEDDER_BATCH_SIZE = "10";

  const embedder = new SampleEmbedder({
    onProgress: (progress) => {
      console.log(
        `  Embedding progress: ${progress.processed}/${progress.total} (${progress.stage})`,
      );
    },
  });

  // Create test texts
  const testTexts = [];
  for (let i = 0; i < 50; i++) {
    testTexts.push(
      `Test text ${i + 1} for embedding generation and batch processing validation.`,
    );
  }

  console.log(
    `Embedding ${testTexts.length} texts with batch size ${embedder.batchSize}...`,
  );
  const startTime = Date.now();

  const embeddings = await embedder.embed(testTexts);

  const duration = Date.now() - startTime;

  console.log(`âœ… Embedding completed in ${duration}ms`);
  console.log(`ðŸ“ Results: ${embeddings.length} embeddings generated`);

  // Cleanup
  delete process.env.RAG_EMBEDDER_BATCH_SIZE;

  return { duration, resultCount: embeddings.length };
}

async function testRetrieverBatching() {
  console.log("\nðŸ”„ Testing Retriever Batching Performance...");

  // Test with environment variable
  process.env.RAG_RETRIEVER_BATCH_SIZE = "20";

  const retriever = new SampleRetriever({
    onProgress: (progress) => {
      console.log(
        `  Retrieval progress: ${progress.processed}/${progress.total} (${progress.stage})`,
      );
    },
  });

  // Store test vectors
  const testVectors = [];
  for (let i = 0; i < 100; i++) {
    testVectors.push(new Array(384).fill(0).map(() => Math.random()));
  }

  console.log(
    `Storing ${testVectors.length} vectors with batch size ${retriever.batchSize}...`,
  );
  const storeStartTime = Date.now();

  await retriever.store(testVectors);

  const storeDuration = Date.now() - storeStartTime;

  console.log(`âœ… Storage completed in ${storeDuration}ms`);

  // Test retrieval
  const queryVector = new Array(384).fill(0).map(() => Math.random());
  const retrieveStartTime = Date.now();

  const results = await retriever.retrieve(queryVector, 50);

  const retrieveDuration = Date.now() - retrieveStartTime;

  console.log(`âœ… Retrieval completed in ${retrieveDuration}ms`);
  console.log(`ðŸ“ Results: ${results.length} documents retrieved`);

  // Cleanup
  delete process.env.RAG_RETRIEVER_BATCH_SIZE;

  return { storeDuration, retrieveDuration, resultCount: results.length };
}

async function testDAGConcurrency() {
  console.log("\nðŸ”„ Testing DAG Concurrency and Timeouts...");

  // Test with environment variable
  process.env.RAG_MAX_CONCURRENCY = "3";
  process.env.RAG_NODE_TIMEOUT = "5000";

  const dag = new DAG();

  // Add nodes with different timeouts
  const node1 = dag.addNode(
    "load",
    async (input) => {
      await new Promise((resolve) => setTimeout(resolve, 100));
      return { data: "loaded", input };
    },
    { timeout: 2000, priority: 1 },
  );

  const node2 = dag.addNode(
    "process",
    async (input) => {
      await new Promise((resolve) => setTimeout(resolve, 150));
      return { processed: input.data };
    },
    { timeout: 3000, priority: 2 },
  );

  const node3 = dag.addNode(
    "finalize",
    async (input) => {
      await new Promise((resolve) => setTimeout(resolve, 50));
      return { final: input.processed };
    },
    { timeout: 1000, priority: 3 },
  );

  // Connect nodes
  node1.addOutput(node2);
  node2.addOutput(node3);

  console.log("Executing DAG with concurrency and timeouts...");
  const startTime = Date.now();

  let progressUpdates = 0;
  const result = await dag.execute(
    { seed: "test" },
    {
      maxConcurrency: 3,
      onProgress: (progress) => {
        progressUpdates++;
        console.log(
          `  DAG progress: ${progress.completed}/${progress.total} nodes (current: ${progress.currentNode})`,
        );
      },
    },
  );

  const duration = Date.now() - startTime;

  console.log(`âœ… DAG execution completed in ${duration}ms`);
  console.log(`ðŸ“Š Progress updates received: ${progressUpdates}`);
  console.log(`ðŸ“ Final result:`, result);

  // Cleanup
  delete process.env.RAG_MAX_CONCURRENCY;
  delete process.env.RAG_NODE_TIMEOUT;

  return { duration, progressUpdates, result };
}

async function testFullPipelinePerformance() {
  console.log("\nðŸ”„ Testing Full Pipeline Performance...");

  const mockLoader = new MockLoader();
  const mockEmbedder = new SampleEmbedder({ batchSize: 25 });
  const mockRetriever = new SampleRetriever({ batchSize: 50 });
  const mockLLM = new MockLLM();

  let progressUpdates = 0;
  const pipeline = createRagPipeline(
    {
      loader: mockLoader,
      embedder: mockEmbedder,
      retriever: mockRetriever,
      llm: mockLLM,
    },
    {
      useReranker: true,
      useParallelProcessing: false,
      onProgress: (progress) => {
        progressUpdates++;
        console.log(
          `  Pipeline progress: ${progress.stage} - ${progress.message || "Processing..."}`,
        );
      },
    },
  );

  console.log("Running full pipeline ingestion...");
  const ingestStartTime = Date.now();

  await pipeline.ingest("test-documents");

  const ingestDuration = Date.now() - ingestStartTime;

  console.log(`âœ… Pipeline ingestion completed in ${ingestDuration}ms`);

  console.log("Running pipeline query...");
  const queryStartTime = Date.now();

  const response = await pipeline.query("What is the test content about?");

  const queryDuration = Date.now() - queryStartTime;

  console.log(`âœ… Pipeline query completed in ${queryDuration}ms`);
  console.log(`ðŸ“ Response: ${response.substring(0, 100)}...`);
  console.log(`ðŸ“Š Progress updates received: ${progressUpdates}`);

  return {
    ingestDuration,
    queryDuration,
    progressUpdates,
    responseLength: response.length,
  };
}

async function runPerformanceTests() {
  console.log("ðŸš€ Starting RAG Pipeline Performance Tests\n");
  console.log(
    "Testing performance improvements while ensuring identical results...\n",
  );

  try {
    const results = {};

    // Test individual components
    results.reranker = await testRerankerBatching();
    results.embedder = await testEmbedderBatching();
    results.retriever = await testRetrieverBatching();
    results.dag = await testDAGConcurrency();
    results.pipeline = await testFullPipelinePerformance();

    console.log("\nðŸ“Š Performance Test Summary:");
    console.log("=====================================");
    console.log(
      `Reranker: ${results.reranker.duration}ms, ${results.reranker.resultCount} docs, ${results.reranker.progressUpdates} progress updates`,
    );
    console.log(
      `Embedder: ${results.embedder.duration}ms, ${results.embedder.resultCount} embeddings`,
    );
    console.log(
      `Retriever: Store ${results.retriever.storeDuration}ms, Retrieve ${results.retriever.retrieveDuration}ms, ${results.retriever.resultCount} results`,
    );
    console.log(
      `DAG: ${results.dag.duration}ms, ${results.dag.progressUpdates} progress updates`,
    );
    console.log(
      `Pipeline: Ingest ${results.pipeline.ingestDuration}ms, Query ${results.pipeline.queryDuration}ms, ${results.pipeline.progressUpdates} progress updates`,
    );

    console.log("\nâœ… All performance tests completed successfully!");
    console.log(
      "ðŸŽ¯ Performance improvements are working correctly with progress feedback.",
    );

    return results;
  } catch (error) {
    console.error("\nâŒ Performance test failed:", error.message);
    console.error(error.stack);
    process.exit(1);
  }
}

// Run tests if this file is executed directly
if (require.main === module) {
  runPerformanceTests()
    .then(() => {
      console.log("\nðŸŽ‰ Performance validation complete!");
      process.exit(0);
    })
    .catch((error) => {
      console.error("\nðŸ’¥ Performance test suite failed:", error.message);
      process.exit(1);
    });
}

module.exports = { runPerformanceTests };
